\section{Results of own implementation}
Table \ref{tab:training-acc} and \ref{tab:training-b_acc} show the mean and 
standard deviation for the accuracy and balanced accuracy of the models during 
nested cross-validation. The authors of the original paper provided a 95\% 
confidence interval for these two measures. Since there is no information on 
how they computed this interval, it is assumed that they used a two-sided 
Student's t-distribution which is used to estimate the mean of normally 
distributed populations where sample size is small. It is calculated using the 
following formula $\bar{x} \pm \frac{t_{\alpha, v}s}{\sqrt{n}}$ where 
$t_{\alpha, v}$ is the t-value which can be taken from a table with $\alpha$ 
as the degrees of freedom $n-1$ and $v$ is the confidence level, $s$ is the 
sample variance, $\bar{x}$ is the sample mean, and $n$ is the number of samples.
For the Random Forest, the 95\% confidence interval of the average accuracy is 
[0.76, 0.80] and of the average balanced accuracy is [0.73, 0.77]. For Logistic 
Regression, the confidence interval of the average accuracy is [0.72, 0.77] and 
of the average balanced accuracy is [0.68, 0,72]. Since the confidence 
intervals of the accuracy and balanced accuracy for both classifiers overlap or 
are near each other, it can be assumed that the slight imbalance of the data 
set had no significant effect on the classifier and that the classifier 
therefore 
is not biased against the outcomes of the target variable. All evaluation 
metrics for each fold and imputed data set are provided in Table 
\ref{tab:storage}.
\par
The best models where selected by searching for the model with the most numbers 
of highest evaluation measures. The best Random Forest Classifier used 
maximally 
4 features, 500 estimators and Gini impurity, it achieved an accuracy of 87.5\% 
and a 
sensitivity of 90\%. The best Logistic Regression Classifier used a C of 10, a 
maximal iteration of 200, the 'l2' penalty and the 'liblinear' solver, it 
achieved an accuracy 
of 83.9\% and a sensitivity of 85\%. These settings were then used to retrain 
the classifiers and compute the validation metrics.
\\
% look at this again and see if there are things you could change
The Random Forest Classifier is also the best performing classifier after 
retraining it with the best hyperparameter with an accuracy of 76.8\% and a 
balanced accuracy of 73.7\%. The Logistic Regression achieves an accuracy of 
73.2\% and a balanced accuracy of 69.4\%. The Decision Tree only achieves an 
accuracy of 71.4\% and a balanced accuracy of 68.5\%. Accordingly, there is 
also no significant difference between the accuracy and balanced accuracy for 
all three classifiers, meaning no classifier is biased.
The aforementioned metrics are lower than the evaluation metrics since the data 
set used to train during the validation phase is different from the one used 
during the evaluation phase due to the way MICE imputes missing data.
All single-threshold metrics are provided in Table \ref{tab:validation-metrics}.
% everything below this needs work
The two multi-threshold metrics, ROC and PRC curve, are shown in Figure 
\ref{fig:prc-roc}. Both plots show that the classifiers perform better than the 
reference line. The values for the area under the ROC and under the PRC curve 
suggest that Logistic Regression (AUC: 80.8\%, AUC (PRC): 85.5\%) performs 
better than the Random Forest (AUC: 80.5\%, AUC (PRC): 82.9\%) although all 
other metrics indicate a better performance for the latter. It 
should be noted that the difference between the AUC scores for both curves are 
minimal and are not meaningful enough to declare the Logistic Regression as the 
better classifier.
\par
Figure \ref{fig:feature-importance} shows all feature importance plots for the 
three classifiers. The feature importance for Decision Tree and Random Forest 
were obtained using the sklearn implementation. The implementation calculates 
the feature importance by quantifying the mean decrease in impurity. 
It should be noted that impurity-based feature importance can suffer 
from favoring features with a high number of unique values as well as making 
predictions based on statistics derived from the training set. This method is 
therefore not necessarily informative about whether a feature makes for a 
good prediction or not.\cite{RN178}
For Logistic Regression, the feature importance is inferred by looking at the 
coefficients of each feature in the data set. A positive coefficient can be 
interpreted as contributing to a positive (1) result and a negative coefficient 
can be interpreted as contributing to a negative (0) result.
It is difficult to compare non tree-based feature importance with tree-based 
importance because they have different scales and means of calculation.
\\
Both tree-based methods show a similar feature importance plot with AST being 
the most important feature. The remaining features are differently distributed, 
but mostly exhibit similar values. Consequently, the Decision Tree and its 
visualization (Figure \ref{fig:dt}) in combination with the feature 
importance plot can be used to give some rough insights into the classification 
procedure of the Random Forest Classifier.

\section{Comparison with original paper}
Most of the metrics measured in this replication are below the values reported 
in the original paper \cite{RN127}. Since there is no documentation of 
individual values during the nested cross validation, only the 95\% confidence 
intervals for the average and the balanced accuracy, it is very difficult to 
compare these results. Additionally, it is also not reported how the authors 
computed the 95\% confidence interval. Nonetheless, most results 
of this replication are still comparable with the original.
